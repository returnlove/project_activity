https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/


Techniques:

1) under sampling of the majority class
2) over sampling of the minority class
3) cluster based over sampling - cluster the intances of both the classes and each cluster should be oversampled such that, all the clusters of the same class have an equal number of instances

Total Observations = 1000

Fraudulent   Observations =20

Non Fraudulent Observations = 980

Event Rate= 2 %

Majority Class Clusters

Cluster 1: 150 Observations
Cluster 2: 120 Observations
Cluster 3: 230 observations
Cluster 4: 200 observations
Cluster 5: 150 observations
Cluster 6: 130 observations

Minority  Class Clusters

Cluster 1: 8 Observations
Cluster 2: 12 Observations
 

After oversampling of each cluster, all clusters of the same class contain the same number of observations.

Majority Class Clusters

Cluster 1: 170 Observations
Cluster 2: 170 Observations
Cluster 3: 170 observations
Cluster 4: 170   observations
Cluster 5: 170   observations
Cluster 6: 170   observations

Minority   Class Clusters

Cluster 1: 250 Observations
Cluster 2: 250 Observations

Event Rate post cluster based oversampling sampling = 500/ (1020+500) = 33 %

Advantages

This clustering technique helps overcome the challenge between class imbalance. Where the number of examples representing positive class differs from the number of examples representing a negative class.
Also, overcome challenges within class imbalance, where a class is composed of different sub clusters. And each sub cluster does not contain the same number of examples.
Disadvantages

The main drawback of this algorithm, like most oversampling techniques is the possibility of over-fitting the training data.



